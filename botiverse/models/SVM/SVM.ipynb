{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"cyan\">Support Vector Machine </font> From Scratch Implementation\n",
    "\n",
    "In this notebook, we shall demonstrate implementing multiclass SVM from scratch using the dual formulation and quadratic programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This module implements and provides an interface for the multiclass Support Vector Machine (SVM) algorithm implemented from scratch.\n",
    "'''\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import cvxopt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    '''\n",
    "    This class implements the kernelized soft-margin Support Vector Machine algorithm.\n",
    "    '''\n",
    "    linear = lambda x, xࠤ , c=0: x @ xࠤ .T\n",
    "    polynomial = lambda x, xࠤ , Q=5: (1 + x @ xࠤ.T)**Q\n",
    "    rbf = lambda x, xࠤ , γ=10: np.exp(-γ * distance.cdist(x, xࠤ, 'sqeuclidean'))\n",
    "    kernel_funs = {'linear': linear, 'polynomial': polynomial, 'rbf': rbf}\n",
    "    \n",
    "    def __init__(self, kernel='rbf', C=1, k=2):\n",
    "        '''\n",
    "        Initialize an instance of the SVM model.\n",
    "        :param kernel: The kernel function to use. Can be 'linear', 'polynomial', or 'rbf'.\n",
    "        :param C: The regularization parameter.\n",
    "        :param k: The hyperparameter for the polynomial and rbf kernels. Ignored for the linear kernel.\n",
    "        '''\n",
    "        self.kernel_str = kernel\n",
    "        self.kernel = SVM.kernel_funs[kernel]\n",
    "        self.C = C\n",
    "        self.k = k\n",
    "        self.X, y = None, None\n",
    "        self.αs = None\n",
    "        # for multi-class classification\n",
    "        self.multiclass = False\n",
    "        self.clfs = []                                  \n",
    "\n",
    "SVMClass = lambda func: setattr(SVM, func.__name__, func) or func"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"white\">Solve the Dual Optimization Problem </font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find the vector of Lagrange multipliers $\\alpha = (\\alpha_1, \\alpha_2, ..., \\alpha_n)$ that maximizes the following dual objective function:\n",
    "\n",
    "$$\n",
    "\\max_\\alpha [ \\sum_{i=1}^{n} \\alpha_i - \\frac{1}{2} \\sum_{i=1}^{n} \\sum_{j=1}^{n} \\alpha_i \\alpha_j y_i y_j (z_iz_j^T) ]\n",
    "\\quad\n",
    "\\text{subject to} \\quad \n",
    "\n",
    "\\sum_{i=1}^{n} \\alpha_i y_i = 0, \\;  0 \\leq \\alpha_i \\leq C, \\; \\forall i = 1, 2, ..., n\n",
    "$$\n",
    "\n",
    "where $z_i = \\phi(x_i)$ and $z_j = \\phi(x_j)$ are higher dimensional representations of $x_i$ and $x_j$ respectively given by the transform $\\phi$.\n",
    "\n",
    "<br>\n",
    "In matrix form, this becomes\n",
    "\n",
    "$$\\max_\\alpha [ 1^Tα - \\frac{1}{2} * α^T (YY^T * K) α ] \\quad\n",
    "\\text{subject to} \\quad\n",
    "y^T \\alpha = 0, \\; 0 \\leq \\alpha_i \\leq C, \\; \\forall i = 1, 2, \\ldots, n\n",
    "$$\n",
    "where $K[i, j] = z_i^T z_j$ and $X$, $y$ are $(N,d)$ and $(N,1)$ dimensional training data matrices respectively.\n",
    "<br>\n",
    "CVXOPT solves\n",
    "\n",
    "$$\n",
    "\\min_x \\frac{1}{2} x^T P x + q^T x \\quad\n",
    "\\text{subject to} \\;  A x = b, \\;G x ≤ h \n",
    "$$\n",
    "\n",
    "Hence, we have\n",
    "<br>\n",
    "$ x = \\alpha $\n",
    "<br>\n",
    "$ P = YY^T * K $\n",
    "<br>\n",
    "$ q = -1^T $\n",
    "<br><br>\n",
    "and for the constraints\n",
    "<br>\n",
    "$ A = y^T $\n",
    "<br>\n",
    "$ b = 0 $\n",
    "<br>\n",
    "$ G = \\begin{bmatrix} -I \\\\ I \\end{bmatrix} $\n",
    "<br>\n",
    "$ h = \\begin{bmatrix} 0 \\\\ C \\end{bmatrix} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@SVMClass\n",
    "def fit(self, X, y, eval_train=False):\n",
    "    '''\n",
    "    Fit the SVM model to the given data with N training examples and d features.\n",
    "    :param X: The training data arranged as a float numpy array of shape (N, d)\n",
    "    :param y: The training labels arranged as a numpy array of shape (N,) where each element is in {-1, 1} or {0, 1}.\n",
    "    :return: None\n",
    "    \n",
    "    :note: This function assume C is not too small; otherwise, it becomes hard to distinguish support vectors.\n",
    "    '''\n",
    "    if len(np.unique(y)) > 2:\n",
    "        self.multiclass = True\n",
    "        return self.multi_fit(X, y, eval_train)\n",
    "    \n",
    "    if set(np.unique(y)) == {0, 1}: y[y == 0] = -1\n",
    "    self.y = y.reshape(-1, 1).astype(np.double) # Has to be a column vector\n",
    "    self.X = X\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    # compute the kernel over all possible pairs of (x, x') in the data\n",
    "    self.K = self.kernel(X, X, self.k)\n",
    "    \n",
    "    # For 1/2 x^T P x + q^T x\n",
    "    P = cvxopt.matrix(self.y @ self.y.T * self.K)\n",
    "    q = cvxopt.matrix(-np.ones((m, 1)))\n",
    "    \n",
    "    # For Ax = b\n",
    "    A = cvxopt.matrix(self.y.T)\n",
    "    b = cvxopt.matrix(np.zeros(1))\n",
    "\n",
    "    # For Gx <= h\n",
    "    G = cvxopt.matrix(np.vstack((-np.identity(m),\n",
    "                                 np.identity(m))))\n",
    "    h = cvxopt.matrix(np.vstack((np.zeros((m,1)),\n",
    "                                 np.ones((m,1)) * self.C)))\n",
    "\n",
    "    # Solve    \n",
    "    cvxopt.solvers.options['show_progress'] = False\n",
    "    sol = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "    self.αs = np.array(sol[\"x\"])\n",
    "        \n",
    "    # Maps into support vectors\n",
    "    self.is_sv = ((self.αs > 1e-3) & (self.αs <= self.C)).squeeze()\n",
    "    self.margin_sv = np.argmax((1e-3 < self.αs) & (self.αs < self.C - 1e-2))\n",
    "    \n",
    "    if eval_train:  print(f\"Model finished training with accuracy {self.evaluate(X, y)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiclass Case with OVR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this, we train $K$ binary classifiers, where $K$ is the number of classes where each classifier perceives one class as +1 and all other classes as -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@SVMClass\n",
    "def multi_fit(self, X, y, eval_train=False):\n",
    "    '''\n",
    "    Fit k classifier for k classes.\n",
    "    :param X: The training data arranged as a float numpy array of shape (N, d)\n",
    "    :param y: The training labels arranged as a numpy array of shape (N,) where each element is an integer between 0 and k-1\n",
    "    :return: None\n",
    "    '''\n",
    "    self.k = len(np.unique(y))      # number of classes\n",
    "    # for each pair of classes\n",
    "    for i in range(self.k):\n",
    "        # get the data for the pair\n",
    "        Xs, Ys = X, copy.copy(y)\n",
    "        # change the labels to -1 and 1\n",
    "        Ys[Ys!=i], Ys[Ys==i] = -1, +1\n",
    "        # fit the classifier\n",
    "        clf = SVM(kernel=self.kernel_str, C=self.C, k=self.k)\n",
    "        clf.fit(Xs, Ys)\n",
    "        # save the classifier\n",
    "        self.clfs.append(clf)\n",
    "    if eval_train:  print(f\"Model finished training with accuracy {self.evaluate(X, y)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a new data point $x$, we predict its label $y$ by computing:\n",
    "\n",
    "$$g(x) = \\sum_{i=1}^{n} \\alpha_i y_i k(x_i, x) + b$$\n",
    "\n",
    "where $k(x_i, x)$ is the kernel function and $b= y_s - \\sum_{i=1}^{n} \\alpha_i y_i k(x_i, x_s)$ is the bias term. $s$ is the index of any margin support vector.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@SVMClass\n",
    "def predict(self, X_t):\n",
    "    '''\n",
    "    Predict the labels for given test data.\n",
    "    :param X_t: The test data arranged as a float numpy array of shape (N, d)\n",
    "    :param return_score: If True, return the score instead of the label.\n",
    "    :return: The predicted labels arranged as a numpy array of shape (N,) where each element is in {-1, 1} or {0, 1} unless return_score is True in which case the SVM score is returned.\n",
    "    '''\n",
    "    if self.multiclass: return self.multi_predict(X_t)\n",
    "    xₛ, yₛ = self.X[self.margin_sv, np.newaxis], self.y[self.margin_sv]\n",
    "    αs, y, X= self.αs[self.is_sv], self.y[self.is_sv], self.X[self.is_sv]\n",
    "\n",
    "    b = yₛ - np.sum(αs * y * self.kernel(X, xₛ, self.k), axis=0)\n",
    "    score = np.sum(αs * y * self.kernel(X, X_t, self.k), axis=0) + b\n",
    "    return np.sign(score).astype(int), score\n",
    "\n",
    "\n",
    "@SVMClass\n",
    "def evaluate(self, X,y):\n",
    "    '''\n",
    "    Compare the predicted labels for given test data y with the actual labels by passing X to model.\n",
    "    :param X: The test data arranged as a float numpy array of shape (N, d)\n",
    "    :param y: The test labels arranged as a numpy array of shape (N,) where each element is an integer between 0 and k-1\n",
    "    '''\n",
    "    outputs, _ = self.predict(X)\n",
    "    accuracy = np.sum(outputs == y) / len(y)\n",
    "    \n",
    "    return round(accuracy, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiclass Case with OVR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each classifier compute the score of a class against all other classes. The class with the highest score is the predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@SVMClass\n",
    "def multi_predict(self, X):\n",
    "    '''\n",
    "    Predict the labels for given test data.\n",
    "    :param X: The test data arranged as a float numpy array of shape (N, d)\n",
    "    :return: The predicted labels arranged as a numpy array of shape (N,) where each element is an integer between 0 and k-1.\n",
    "    '''\n",
    "    # get the predictions from all classifiers\n",
    "    preds = np.zeros((X.shape[0], self.k))\n",
    "    for i, clf in enumerate(self.clfs):\n",
    "        _, preds[:, i] = clf.predict(X)\n",
    "    \n",
    "\n",
    "    # transform the predictions into probabilities using softmax\n",
    "    preds = np.exp(preds) / np.sum(np.exp(preds), axis=1, keepdims=True)    \n",
    "    \n",
    "    # get the argmax and the corresponding score\n",
    "    return np.argmax(preds, axis=1), np.max(preds, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook SVM.ipynb to script\n",
      "[NbConvertApp] Writing 9050 bytes to SVM.py\n"
     ]
    }
   ],
   "source": [
    "# if running from notebook\n",
    "if __name__ == '__main__':\n",
    "    !jupyter nbconvert --to script SVM.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "M1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
