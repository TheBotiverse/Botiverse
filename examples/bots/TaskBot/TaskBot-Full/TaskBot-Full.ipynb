{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from botiverse import chat_gui\n",
        "from botiverse.bots import TaskBot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7gpppja-weh"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KFNex6XNjHiy"
      },
      "outputs": [],
      "source": [
        "# The domains e.g. restaurant, hotel, etc.\n",
        "domains = [\"restaurant\"]\n",
        "\n",
        "# The names of the slots where each slot is prefixed with the domain name e.g. restaurant-name, hotel-name, etc.\n",
        "slot_list = [\n",
        "    \"restaurant-category\",\n",
        "    \"restaurant-rating\",\n",
        "    \"restaurant-num_people\",\n",
        "    \"restaurant-location\",\n",
        "    \"restaurant-restaurant_name\",\n",
        "    \"restaurant-time\",\n",
        "    \"restaurant-date\",\n",
        "    \"restaurant-price_range\",\n",
        "    \"restaurant-meal\"\n",
        "]\n",
        "\n",
        "# The utterances for the system to start the conversation\n",
        "start = [\n",
        "    {\n",
        "        'utterance': 'Hi I am Tody, I can help you reserve a restaurant?',\n",
        "        'slots': [],\n",
        "        'system_act': {}\n",
        "    }\n",
        "]\n",
        "\n",
        "# The templates for generating responses\n",
        "templates = [\n",
        "    {\n",
        "        'utterance': 'what type of food do you want and in what area?',\n",
        "        'slots': ['restaurant-location', 'restaurant-category'],\n",
        "        'system_act': {}\n",
        "    },\n",
        "    {\n",
        "        'utterance': 'what is your preferred price range and rating?',\n",
        "        'slots': ['restaurant-price_range', 'restaurant-rating'],\n",
        "        'system_act': {}\n",
        "    },\n",
        "    {\n",
        "        'utterance': 'how many people will be in your party?',\n",
        "        'slots': ['restaurant-num_people'],\n",
        "        'system_act': {}\n",
        "    },\n",
        "    {\n",
        "        'utterance': 'what time and date would you like to reserve a table for?',\n",
        "        'slots': ['restaurant-time', 'restaurant-date'],\n",
        "        'system_act': {}\n",
        "    },\n",
        "    {\n",
        "        'utterance': 'May I suggest kfc restaurant?',\n",
        "        'slots': ['restaurant-restaurant_name'],\n",
        "        'system_act': {'restaurant-restaurant_name': ['kfc']}\n",
        "    },\n",
        "    {\n",
        "        'utterance': 'ok done, here is your reservation number: 123456',\n",
        "        'slots': [],\n",
        "        'system_act': {}\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nN2fVS6F-zo0"
      },
      "source": [
        "## Create chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUjWVWDwlAuP",
        "outputId": "7bfb5119-534e-46f3-9651-99b79bbe8c72"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "chatbot = TaskBot(domains, slot_list, start, templates, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Give data to the chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_path = 'sim-R_dataset/train_dials.json'\n",
        "dev_path = 'sim-R_dataset/dev_dials.json'\n",
        "test_path = 'sim-R_dataset/test_dials.json'\n",
        "\n",
        "chatbot.read_data(train_path, dev_path, test_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nM1AWHHX-1fG"
      },
      "source": [
        "# Train the chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXE8j07VlChR",
        "outputId": "4ff75074-5286-4653-b664-cfc71cc816fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing train set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6175/6175 [00:03<00:00, 1922.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing dev set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1489/1489 [00:00<00:00, 2339.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing test set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3436/3436 [00:01<00:00, 1977.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0 ---------------------------------------------------------------\n",
            "Training the model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/193 [00:16<?, ?it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32md:\\programing\\faculty of engineering\\5_fourth year in cmp\\GP\\Botiverse\\examples\\bots\\TaskBot\\TaskBot-Full\\TaskBot-Full.ipynb Cell 10\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/programing/faculty%20of%20engineering/5_fourth%20year%20in%20cmp/GP/Botiverse/examples/bots/TaskBot/TaskBot-Full/TaskBot-Full.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m chatbot\u001b[39m.\u001b[39;49mtrain()\n",
            "File \u001b[1;32md:\\programing\\faculty of engineering\\5_fourth year in cmp\\gp\\botiverse\\botiverse\\bots\\TaskBot\\TaskBot.py:99\u001b[0m, in \u001b[0;36mTaskBot.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     95\u001b[0m   \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[39m  Train the chatbot model with the given training data.\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \n\u001b[0;32m     98\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdst\u001b[39m.\u001b[39;49mtrain(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_path, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdev_path, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_path)\n",
            "File \u001b[1;32md:\\programing\\faculty of engineering\\5_fourth year in cmp\\gp\\botiverse\\botiverse\\models\\TRIPPY\\TRIPPY_DST.py:151\u001b[0m, in \u001b[0;36mTRIPPYDST.train\u001b[1;34m(self, train_path, dev_path, test_path)\u001b[0m\n\u001b[0;32m    148\u001b[0m model_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(curr_dir, \u001b[39m'\u001b[39m\u001b[39mmodel.pt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    150\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m run(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdomains, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mslot_list, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_maps, train_path, dev_path, test_path, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnon_referable_slots, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnon_referable_pairs, model_path, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mTRIPPY_config)\n",
            "File \u001b[1;32md:\\programing\\faculty of engineering\\5_fourth year in cmp\\gp\\botiverse\\botiverse\\models\\TRIPPY\\run.py:102\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(model, domains, slot_list, label_maps, train_path, dev_path, test_path, device, non_referable_slots, non_referable_pairs, model_path, TRIPPY_config)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m ---------------------------------------------------------------\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    101\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTraining the model...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 102\u001b[0m train(train_data_loader, model, optimizer, device, scheduler, n_slots, TRIPPY_config\u001b[39m.\u001b[39;49mignore_idx, TRIPPY_config\u001b[39m.\u001b[39;49moper2id)\n\u001b[0;32m    103\u001b[0m \u001b[39mif\u001b[39;00m dev_path \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    104\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEvaluating the model on dev set...\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[1;32md:\\programing\\faculty of engineering\\5_fourth year in cmp\\gp\\botiverse\\botiverse\\models\\TRIPPY\\train.py:141\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(data_loader, model, optimizer, device, scheduler, n_slots, ignore_idx, oper2id)\u001b[0m\n\u001b[0;32m    138\u001b[0m   batch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m total_loss\u001b[39m.\u001b[39msum()\n\u001b[0;32m    140\u001b[0m \u001b[39m# batch_loss /= n_slots\u001b[39;00m\n\u001b[1;32m--> 141\u001b[0m batch_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m    142\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), \u001b[39m1.0\u001b[39m)\n\u001b[0;32m    143\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
            "File \u001b[1;32md:\\programing\\programs\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
            "File \u001b[1;32md:\\programing\\programs\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "chatbot.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Save the trained chatbot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "save_path = 'model.pt'\n",
        "chatbot.save_model(save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soaqWfYk-7DN"
      },
      "source": [
        "# load saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXKYKWEHld5I",
        "outputId": "b24f8803-a754-4afa-878a-278fe92f9746"
      },
      "outputs": [],
      "source": [
        "chatbot.load_dst_model(save_path, test_path=test_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run chatbot using GUI from botiverse\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app 'botiverse.gui.gui'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<botiverse.gui.gui.chat_gui at 0x2e70a63a0>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat_gui('Task Bot', chatbot.infer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "uqSL1SM8jTmN",
        "lUwJn3GGkAeJ",
        "xL8SWbdag55U",
        "OGMX4sV0hPm2",
        "OHprhkophXcd",
        "jWPsHYnQhZeC",
        "y0Gj-tIcixed",
        "s1wW97HBi_SR",
        "eZeVgmAYjA1T"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
